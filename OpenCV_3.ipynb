{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b91f681-0188-484f-94cc-47827860b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8df5ab9-b08a-475a-ba28-4d05b85d9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfaf7c7f-6c11-4b26-ad00-6a71a2278a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input=cv2.imread(\"OpenCV/SampleImages/Trump.jpg\")\n",
    "# cv2.imshow(\"Sample\",input)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91f2103-1a87-4ed4-aa47-2ef204f3d3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection using HAAR classifier\n",
    "face_classifier = cv2.CascadeClassifier(\"OpenCV/HaarCascade/haarcascade_frontalface_default.xml\")\n",
    "# We should convert the image to grayscale\n",
    "\n",
    "gray = cv2.cvtColor(input,cv2.COLOR_BGR2GRAY)\n",
    "faces=face_classifier.detectMultiScale(gray,1.3,5)\n",
    "if len(faces)==0:\n",
    "    print(\"NO faces found\")\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(input,(x,y),(x+w,y+h),(127,123,18),2)\n",
    "cv2.imshow(\"Face Detection image\",input)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913ef2f6-37b9-4601-808b-decf93aaebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input=cv2.imread(\"OpenCV/SampleImages/Trump.jpg\")\n",
    "# cv2.imshow(\"Sample\",input)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac286f7-5b72-417b-8a3e-a0905770d8b8",
   "metadata": {},
   "source": [
    "MULTISCALE IN CASCADE CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23560bbb-a11b-44ba-ae07-2660538b50ed",
   "metadata": {},
   "source": [
    "detectMultiScale (image_name, scale_factor, minSize)\n",
    "\n",
    "üß© SCALE FACTOR: \n",
    "    The scaleFactor in detectMultiScale controls how much the image size is reduced at each image scale. When you set it to 1.1, it means the image is reduced by 10% at each step of the image pyramid.\n",
    "\n",
    "Here‚Äôs why that's helpful:\n",
    "A smaller scale factor (like 1.1) means the algorithm checks more potential sizes for objects, increasing the likelihood of detecting eyes at slightly different sizes. It's more precise but also slightly slower.\n",
    "A larger scale factor (like 1.4 or 1.5) skips more steps, making the process faster, but it might miss smaller or less obvious features.\n",
    "\n",
    "So, 1.1 strikes a good balance between detection accuracy and performance, especially for small features like eyes that can vary subtly in size between people or frames.\n",
    "\n",
    "üß© minNeighbors\n",
    "    This one controls how many ‚Äúvotes‚Äù a region needs before it‚Äôs declared as a detection. Think of it like eye detection going through peer review:\n",
    "    \n",
    "A higher value (like 6‚Äì10) = more confidence needed = fewer but more accurate detections.\n",
    "A lower value (like 3‚Äì5) = looser rules = more detections, but may include false positives (like calling a shadow an ‚Äúeye‚Äù).\n",
    "\n",
    "For eye detection, values between 6 and 10 often work well, since eyes are small and symmetrical but vary a lot.\n",
    "\n",
    "üìè minSize=(30, 30)\n",
    "\n",
    "This filters out detections that are too small to be real eyes.\n",
    "30x30 means: ‚ÄúOnly detect things that are at least 30 pixels wide and tall.‚Äù\n",
    "\n",
    "You can lower this if you're working with high-resolution images or zoomed-out faces, like minSize=(20, 20), but go too small and you'll detect noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "131016d2-7852-41fa-89ba-81af6937530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eye classifier using HAAR CLASSIFIER\n",
    "eye_classifier=cv2.CascadeClassifier(\"OpenCV/HaarCascade/haarcascade_eye.xml\")\n",
    "gray=cv2.cvtColor(input,cv2.COLOR_BGR2GRAY)\n",
    "eyes = eye_classifier.detectMultiScale(gray,1.1 , 10)\n",
    "for x,y,w,h in eyes:\n",
    "    cv2.rectangle(input,(x,y),(x+w,y+h),(120,53,200),2)\n",
    "    cv2.imshow(\"eye detection\",input)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9da89e-a94f-4c10-b97f-9b3036b2b2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO FACES DETECTED\n",
      "NO EYES DETECTED\n"
     ]
    }
   ],
   "source": [
    "input=cv2.imread(\"OpenCV/SampleImages/elephant.jpg\")\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"OpenCV/HaarCascade/haarcascade_frontalface_default.xml\")\n",
    "eye_classifier=cv2.CascadeClassifier(\"OpenCV/HaarCascade/haarcascade_eye.xml\")\n",
    "\n",
    "# We should convert the image to grayscale\n",
    "gray = cv2.cvtColor(input,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"eye detection\",input)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "faces=face_classifier.detectMultiScale(gray,scaleFactor=1.3,minNeighbors=5,minSize=(30,30))\n",
    "eyes=eye_classifier.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=10,minSize=(30,30))\n",
    "    \n",
    "if len(faces)==0:\n",
    "    print(\"NO FACES DETECTED\")\n",
    "if len(eyes)==0:\n",
    "    print(\"NO EYES DETECTED\")\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(input,(x,y),(x+w,y+h),(127,123,18),2)\n",
    "    cv2.imshow(\"Face Detection image\",input)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    for a,b,c,d in eyes:\n",
    "        cv2.rectangle(input,(a,b),(a+c,b+d),(120,53,200),2)\n",
    "        cv2.imshow(\"eye detection\",input)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf92ee-c1bc-4b0e-bcd4-1afcaf7ed7f7",
   "metadata": {},
   "source": [
    "CAR DETECTION: (using HAAR cascade classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "129c609a-7a23-483b-94e4-83321797c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_classifier=cv2.CascadeClassifier(\"OpenCV/HaarCascade/haarcascade_car.xml\")\n",
    "car_input=cv2.imread(\"OpenCV/SampleImages/cars_on_road.jpg\")\n",
    "gray=cv2.cvtColor(car_input,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Cars image\",gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8571b08d-4835-4376-98a6-e097d87b605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=car_classifier.detectMultiScale(gray,1.05,4,minSize=(30,30))\n",
    "if len(cars)==0:\n",
    "    print(\"NO CARS FOUND\")\n",
    "for x,y,w,h in cars:\n",
    "    cv2.rectangle(car_input,(x,y),(x+w,y+h),(123,12,165),2)\n",
    "    cv2.imshow(\"Cars image\",car_input)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ec96d-3951-4725-b20b-af418dca8a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
